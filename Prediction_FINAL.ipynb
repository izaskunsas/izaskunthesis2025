{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd2Hz5OxAbwSTfPmRmXkcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izaskunsas/izaskunthesis2025/blob/main/Prediction_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***PREDICTION ANALYSIS***\n",
        "## **SETTING THE SESSION**"
      ],
      "metadata": {
        "id": "v1NRHhNVBYuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "18E7_SzhBndE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1b7h21Q3Bikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import shap"
      ],
      "metadata": {
        "id": "hSOoE8YeFq7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/THESIS/Code/data/data_FINAL\", index_col=0)"
      ],
      "metadata": {
        "id": "ndWRpsiACpsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[~data['league'].isin(['ukraine_league', 'finland_league', 'czechia_league', 'greece_league'])]"
      ],
      "metadata": {
        "id": "FERR9Zh0Crhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.value_counts('league')"
      ],
      "metadata": {
        "id": "aK6Y31eMCw0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SPLIT - Splitting by year and i'm not removing temporal componetns because\n",
        "train_years = ['FIFA 15', 'FIFA 16', 'FIFA 17', 'FIFA 18', 'FIFA 19', 'FIFA 20', 'FIFA 21']\n",
        "data_trainval = data[data['Year'].isin(train_years)]\n",
        "\n",
        "val_years   = ['FIFA 22', 'FIFA 23']\n",
        "data_val = data[data['Year'].isin(val_years)]\n",
        "\n",
        "test_years  = ['FC 24', 'FC 25']\n",
        "data_test = data[data['Year'].isin(test_years)]\n",
        "\n",
        "#SEPARATE OUTPUT VARIABLE\n",
        "X_trainval = data_trainval.drop(columns=['league', 'Year', 'name', 'team', 'nation', 'position'])\n",
        "y_trainval = data_trainval['league']\n",
        "\n",
        "X_val = data_val.drop(columns=['league', 'Year', 'name', 'team', 'nation', 'position'])\n",
        "y_val = data_val['league']\n",
        "\n",
        "X_test = data_test.drop(columns=['league', 'Year', 'name', 'team', 'nation', 'position'])\n",
        "y_test = data_test['league']\n",
        "\n",
        "#TRAIN SPLIT -- for hyperparameter tuning into train and validation, stratified by league so they are more or less equal in the tuning of the model\n",
        "X_train, X_val_strat, y_train, y_val_strat = train_test_split(\n",
        "    X_trainval,\n",
        "    y_trainval,\n",
        "    test_size=0.2,  # 20% for validation\n",
        "    random_state=22,\n",
        "    stratify=y_trainval\n",
        ")"
      ],
      "metadata": {
        "id": "imY6ae52DABp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leagues = ['english_premier_league', 'spain_la_liga', 'italy_serie_a', 'france_ligue_1',\n",
        "           'german_bundesliga', 'poland_league', 'nl_eredivisie', 'portugal_liga',\n",
        "           'belgium_league', 'norway_league', 'sweden_league', 'denmark_superliga',\n",
        "           'austria_bundesliga', 'switzerland_league', 'scotland_prem', 'ireland_league']"
      ],
      "metadata": {
        "id": "PH4qkwApDB5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**EVALUATION FUNCTIONS**"
      ],
      "metadata": {
        "id": "hGL5G5hLDEvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFUSION MATRIX\n",
        "\n",
        "def plot_confusion_matrix(model, X_val, y_val, title, labels= np.unique(y_train)):\n",
        "    os.makedirs('/content/drive/MyDrive/THESIS/Code/plots/Prediction/', exist_ok=True)\n",
        "    y_predicted = model.predict(X_val)\n",
        "    cm = confusion_matrix(y_val, y_predicted)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 8})\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True Label')\n",
        "    #plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/THESIS/Code/plots/Prediction/{title}.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    acc = accuracy_score(y_val, y_predicted)\n",
        "    print('test_accuracy: %.3f' % (acc))\n",
        "    return"
      ],
      "metadata": {
        "id": "C0ngkzs6DPzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix_filtered(model, X_val, y_val, title, labels=np.unique(y_val)):\n",
        "    os.makedirs('/content/drive/MyDrive/THESIS/Code/plots/Prediction/', exist_ok=True)\n",
        "    y_predicted = model.predict(X_val)\n",
        "    cm = confusion_matrix(y_val, y_predicted)\n",
        "\n",
        "    threshold = 100\n",
        "    filter = np.where(cm > threshold, cm.astype(str), '')\n",
        "\n",
        "    sns.heatmap(cm, annot=filter, cmap='Blues', fmt='', xticklabels=labels, yticklabels=labels,\n",
        "                cbar=True, linewidths=0.5, linecolor='white', annot_kws={\"size\": 8})\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True Label')\n",
        "    #plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/THESIS/Code/plots/Prediction/{title}.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    acc = accuracy_score(y_val, y_predicted)\n",
        "    print('test_accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "7LRRWJueDai-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PERFORMANCE MEASURES DATA\n",
        "\n",
        "def calculate_metrics(model, X_val, y_val):\n",
        "    # predict probabilities for the set\n",
        "    y_predicted = model.predict(X_val)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_val, y_predicted)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_val, y_predicted, average=None)\n",
        "    print('Precision:', precision)\n",
        "\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_val, y_predicted, average=None)\n",
        "    print('Recall:', recall)\n",
        "\n",
        "    # weighted-f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_val, y_predicted, average=None)\n",
        "    print('F1 score:', f1)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "0U1eNGAuDct3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRID SEARCH\n",
        "def calculate_best_params(model, grid, X_train):\n",
        "    model  = model();\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, cv = 3, verbose = 3, n_jobs=-1)\n",
        "\n",
        "    grid_search.fit(X_train,y_train)\n",
        "\n",
        "    print(\"Best Parameters:\",grid_search.best_params_)\n",
        "    print(\"Train Score:\",grid_search.best_score_)\n",
        "    print(\"Val Score:\",grid_search.score(X_val_strat,y_val_strat))"
      ],
      "metadata": {
        "id": "9ZFkVtyPDR23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**BASELINE MODEL**\n",
        "Multinominal Logistic Regression"
      ],
      "metadata": {
        "id": "JKI5uzjhDheQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver = 'lbfgs',\n",
        "    max_iter=1000,\n",
        "    random_state=22,\n",
        ")\n",
        "\n",
        "baseline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "I8po9XcUDgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(baseline, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "7TbzyGS8D_jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(baseline, X_val_strat, y_val_strat, title = \"CM Baseline\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "Zom_MsurEBNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(baseline, X_val_strat, y_val_strat, title = \"SIMPLE CM Baseline\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "-rU4DBeOEDaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grid Search\n",
        "Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "nouvELquEJ9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_grid = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None],  # Regularization\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],               # Inverse of regularization strength\n",
        "    'solver': ['saga'],\n",
        "    'l1_ratio': [0, 0.5, 1],\n",
        "    'max_iter': [5000]\n",
        "}\n",
        "\n",
        "calculate_best_params(LogisticRegression, log_grid)\n",
        "\n",
        "# Best Parameters: {'C': 10, 'l1_ratio': 0, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'saga'}\n",
        "# Train Score: 0.26744124064105573\n",
        "# Val Score: 0.2700522608498069"
      ],
      "metadata": {
        "id": "OGxqJe8BEJJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optuna\n",
        "(did not work)"
      ],
      "metadata": {
        "id": "Xc7gGSGvER9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "\n",
        "#https://www.kaggle.com/code/bextuychiev/no-bs-guide-to-hyperparameter-tuning-with-optuna\n",
        "# Source/inspiration: https://www.kaggle.com/discussions/general/261870\n",
        "\n",
        "def objective(trial):\n",
        "    #Hyperparameters Logistic Regression\n",
        "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\", None])\n",
        "    solver = \"saga\"  # saga supports all penalties\n",
        "    C = trial.suggest_loguniform(\"C\", 1e-4, 1e2)\n",
        "    l1_ratio = None\n",
        "    if penalty == \"elasticnet\":\n",
        "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
        "\n",
        "    ####\n",
        "    model = LogisticRegression(\n",
        "        penalty=penalty,\n",
        "        C=C,\n",
        "        l1_ratio=l1_ratio,\n",
        "        solver=solver,\n",
        "        max_iter=5000,\n",
        "        multi_class=\"multinomial\"\n",
        "    )\n",
        "\n",
        "    #Cross-validation\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ],
      "metadata": {
        "id": "GrVQB4GVEaa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SVM**"
      ],
      "metadata": {
        "id": "apqZvShbFUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "svm_model = SVC(\n",
        "    C=10,\n",
        "    kernel = 'rbf',\n",
        "    gamma = 0.01,\n",
        "    random_state=22\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "u4YC9oziG33o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(svm_model, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "NczuvHFjG5ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(svm_model, X_val_strat, y_val_strat, title = \"CM SVM\")"
      ],
      "metadata": {
        "id": "z5hGXShPG7bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(svm_model, X_val_strat, y_val_strat, title = \"SIMPLE CM SVM\")"
      ],
      "metadata": {
        "id": "8nBVTY0mG9D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grid Search"
      ],
      "metadata": {
        "id": "P7lnREYQHDYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM - GridSearch\n",
        "#https://www.kaggle.com/code/gorkemgunay/understanding-parameters-of-svm\n",
        "\n",
        "svm_grid = {\n",
        "    'C':[0.01,0.1,1,10],\n",
        "    'kernel' : [\"rbf\",\"sigmoid\"],\n",
        "    'gamma' : [0.01,1,10,500]\n",
        "}\n",
        "\n",
        "calculate_best_params(SVC, svm_grid, X_train)\n",
        "\n",
        "#Best Parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
        "#Train Score: 0.40176234514046416\n",
        "#Val Score: 0.4289868558799581"
      ],
      "metadata": {
        "id": "p6yYUSXWHEXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**CatBoost**"
      ],
      "metadata": {
        "id": "-1sT2Im2FXQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CATBOOST\n",
        "#https://www.kaggle.com/code/prashant111/catboost-classifier-in-python#\n",
        "#used the hyperparameters of (Malamatinos, Vrochidou & Papakostas, 2022)\n",
        "\n",
        "cb_model = CatBoostClassifier(\n",
        "    iterations = 40,\n",
        "    learning_rate = 0.05,\n",
        "    l2_leaf_reg = 3,\n",
        "    depth = 6,\n",
        "    loss_function = 'MultiClass'\n",
        ")\n",
        "\n",
        "cb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eX6yA94FHLgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(cb_model, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "zr7HXloXHN8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cb_model, X_val_strat, y_val_strat, title = \"CM CatBoost\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "nnpO14lNHOSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(cb_model, X_val_strat, y_val_strat, title = \"SIMPLE CM CatBoost\")"
      ],
      "metadata": {
        "id": "wSbjkU0fHQzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search"
      ],
      "metadata": {
        "id": "18mK8TCEHULz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'depth': [4, 6, 8],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7],\n",
        "    'iterations': [100, 300],\n",
        "    'border_count': [32, 64, 128],  # Number of splits for numeric features\n",
        "    'loss_function':['MultiClass']\n",
        "}\n",
        "calculate_best_params(CatBoostClassifier, cb_grid, X_train)\n",
        "\n",
        "#Best Parameters: {'border_count': 32, 'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1, 'learning_rate': 0.1, 'loss_function': 'MultiClass'}\n",
        "#Train Score: 0.5321060896876636\n",
        "#Val Score: 0.5699662673025474"
      ],
      "metadata": {
        "id": "WAU7TwCCHVsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb_model_hypertuned = CatBoostClassifier(\n",
        "    iterations = 300,\n",
        "    learning_rate = 0.1,\n",
        "    border_count = 32,\n",
        "    l2_leaf_reg = 1,\n",
        "    depth = 8,\n",
        "    loss_function = 'MultiClass'\n",
        ")\n",
        "\n",
        "cb_model_hypertuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LRs6K7mFHXwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(cb_model_hypertuned, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "i4zlH41WHYOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cb_model_hypertuned, X_val_strat, y_val_strat, title = \"CM CatBoost Best\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "InYaju4JHbFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(cb_model_hypertuned, X_val_strat, y_val_strat, title = \"SIMPLE CM CatBoost Best\")"
      ],
      "metadata": {
        "id": "b3WqrCAeHcVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**RANDOM FOREST**\n",
        "Best Performing Model"
      ],
      "metadata": {
        "id": "-mfIHI97Eenv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=22,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QXh9skOHEd2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(rf_model, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "jG4v5d5MEnCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(rf_model, X_val_strat, y_val_strat, title = \"CM Random Forest\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "Felln4sqEoQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(rf_model, X_val_strat, y_val_strat, title = \"SIMPLE CM Random Forest\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "rqImQh9EEr3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search"
      ],
      "metadata": {
        "id": "3ySrxQffExCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.blog.trainindata.com/random-forest-with-grid-search/\n",
        "rf_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200, 250],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "calculate_best_params(RandomForestClassifier, rf_grid, X_train)\n",
        "\n",
        "#Best Parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
        "#Train Score: 0.5606060606060606\n",
        "#Val Score: 0.6274281726183553"
      ],
      "metadata": {
        "id": "Gb3ADt0ZEwt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BEST PERFORMANCE"
      ],
      "metadata": {
        "id": "H_BhMMGkFFrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model_best = RandomForestClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=None,\n",
        "    max_features = 'log2',\n",
        "    min_samples_leaf = 1,\n",
        "    min_samples_split = 2,\n",
        "    random_state=22,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KrgBJjooE3io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(rf_model_best, X_val_strat, y_val_strat)"
      ],
      "metadata": {
        "id": "EA-DInmKE_tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(rf_model_best, X_val_strat, y_val_strat, title = \"CM Random Forest Best\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "JdYmZXyTFAJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(rf_model_best, X_val_strat, y_val_strat, title = \"SIMPLE CM Random Forest Best\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "kBe7Dp8nFDZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###HOLD OUT SET"
      ],
      "metadata": {
        "id": "viCpgsGkFIBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model_test = RandomForestClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=None,\n",
        "    max_features = 'log2',\n",
        "    min_samples_leaf = 1,\n",
        "    min_samples_split = 2,\n",
        "    random_state=22,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model_test.fit(X_val, y_val)"
      ],
      "metadata": {
        "id": "m2oLm8idFLCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(rf_model_test, X_test, y_test)"
      ],
      "metadata": {
        "id": "ELbsH8tdFMJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(rf_model_test, X_test, y_test, title = \"CM Random Forest Test\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "Zr1tyeXgFOZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix_filtered(rf_model_test, X_test, y_test, title = \"SIMPLE CM Random Forest Test\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "8J1Fio7OFSDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FEATURE IMPORTANCE\n",
        "SHAP"
      ],
      "metadata": {
        "id": "Kjji5nTVFc0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST FEATURE IMPORTANCE\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=22,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "avQV-UqnJIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(rf_model)"
      ],
      "metadata": {
        "id": "mDyaCZUMJLVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer.shap_values(X_val_strat)"
      ],
      "metadata": {
        "id": "dpiY2GxmJNZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUMMARY PLOTS PER LEAGUE\n",
        "shap_values_by_class = [shap_values[:, :, i] for i in range(shap_values.shape[2])]\n",
        "for i, league in enumerate(leagues):\n",
        "    print(f\"Plotting SHAP summary for class: {league}\")\n",
        "    shap.summary_plot(shap_values_by_class[i], X_val_strat, show=False)\n",
        "    plt.title(f\"SHAP Summary Plot - {league}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"shap_summary_{league.replace(' ', '_')}.png\")\n",
        "    plt.clf()"
      ],
      "metadata": {
        "id": "4PuO9RDKJPZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUMMARY PLOT -- OVERALL MEAN\n",
        "#debugged by ChatGPT\n",
        "shap_values_mean = np.mean(np.abs(shap_values), axis=2)  # shape = (n_samples, n_features)\n",
        "\n",
        "shap.summary_plot(shap_values_mean, X_val_strat)"
      ],
      "metadata": {
        "id": "pne_nq_XJdkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUMMARY PLOT -- OVERALL MAX\n",
        "shap_values_max = np.max(np.abs(shap_values), axis=2)\n",
        "\n",
        "shap.summary_plot(shap_values_max, X_val_strat)"
      ],
      "metadata": {
        "id": "zpIoMUhYJiya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUMMARY PLOT -- OVERALL SUM\n",
        "shap_values_sum = np.sum(np.abs(shap_values), axis=2)\n",
        "\n",
        "shap.summary_plot(shap_values_max, X_val_strat)"
      ],
      "metadata": {
        "id": "x_aVrBEjJtgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of fewer features"
      ],
      "metadata": {
        "id": "bz0DntL0J-8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VERSION 1 - Subset 8 leagues\n",
        "shap_feature_importance = np.abs(predicted_class_shap).mean(axis=0)\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_val_strat.columns,\n",
        "    'Importance': shap_feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importance_df.to_csv('feature_importance_SHAP.csv')\n",
        "\n",
        "# --- Helper Function to Train with Top-N Features ---\n",
        "def evaluate_rf_with_top_features(top_ns):\n",
        "    best_results = []\n",
        "\n",
        "    for top_n in top_ns:\n",
        "        print(f\"\\nEvaluating top {top_n} features...\")\n",
        "\n",
        "        selected_features = feature_importance_df.head(top_n)['Feature'].tolist()\n",
        "\n",
        "\n",
        "        X_train_filter = X_train[selected_features]\n",
        "        X_val_filter = X_val[selected_features]\n",
        "\n",
        "        leagues_to_keep = [\n",
        "            'english_premier_league', 'spain_la_liga', 'italy_serie_a',\n",
        "            'france_ligue_1', 'german_bundesliga', 'nl_eredivisie',\n",
        "            'portugal_liga', 'scotland_prem'\n",
        "        ]\n",
        "\n",
        "        mask_train = y_train.isin(leagues_to_keep)\n",
        "        mask_val = y_val.isin(leagues_to_keep)\n",
        "\n",
        "        X_train_top = X_train_filter[mask_train].reset_index(drop=True)\n",
        "        y_train_top = y_train[mask_train].reset_index(drop=True)\n",
        "\n",
        "        X_val_top = X_val_filter[mask_val].reset_index(drop=True)\n",
        "        y_val_top = y_val[mask_val].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5]\n",
        "        }\n",
        "        grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)\n",
        "        grid.fit(X_train_top, y_train_top)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(X_val_top)\n",
        "        acc = accuracy_score(y_val_top, y_pred)\n",
        "\n",
        "        print(f\"Top-{top_n} features | Accuracy: {acc:.4f} | Best Params: {grid.best_params_}\")\n",
        "        best_results.append((top_n, acc, grid.best_params_))\n",
        "\n",
        "    return best_results\n",
        "\n",
        "\n",
        "top_n_list = [5, 10, 15, 20, 25, 30, 35]\n",
        "results = evaluate_rf_with_top_features(top_n_list)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Top_N', 'Accuracy', 'Best_Params'])\n",
        "print(\"\\nSummary:\\n\", results_df)"
      ],
      "metadata": {
        "id": "pzsR9MtHKB2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VERSION 2 - 16 leagues\n",
        "# Get mean absolute SHAP value per feature\n",
        "shap_feature_importance = np.abs(predicted_class_shap).mean(axis=0)\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_val_strat.columns,\n",
        "    'Importance': shap_feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importance_df.to_csv('feature_importance_SHAP.csv')\n",
        "\n",
        "# --- Helper Function to Train with Top-N Features ---\n",
        "def evaluate_rf_with_top_features(top_ns):\n",
        "    best_results = []\n",
        "\n",
        "    for top_n in top_ns:\n",
        "        print(f\"\\nEvaluating top {top_n} features...\")\n",
        "\n",
        "        selected_features = feature_importance_df.head(top_n)['Feature'].tolist()\n",
        "\n",
        "        # Apply feature mask\n",
        "        X_train_filter = X_train[selected_features]\n",
        "        X_val_filter = X_val[selected_features]\n",
        "\n",
        "        # Train RF with grid search\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5]\n",
        "        }\n",
        "        grid = GridSearchCV(RandomForestClassifier(random_state=22), param_grid, cv=3, n_jobs=-1)\n",
        "        grid.fit(X_train_filter, y_train)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(X_val_filter)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        print(f\"Top-{top_n} features | Accuracy: {acc:.4f} | Best Params: {grid.best_params_}\")\n",
        "        best_results.append((top_n, acc, grid.best_params_))\n",
        "\n",
        "    return best_results\n",
        "\n",
        "# Run evaluation\n",
        "top_n_list = [5, 10, 15, 20, 25, 30, 35]\n",
        "results = evaluate_rf_with_top_features(top_n_list)\n",
        "\n",
        "# Display summary\n",
        "results_df = pd.DataFrame(results, columns=['Top_N', 'Accuracy', 'Best_Params'])\n",
        "print(\"\\nSummary:\\n\", results_df)"
      ],
      "metadata": {
        "id": "uWlYBQOAKOPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other plots"
      ],
      "metadata": {
        "id": "NNAm4kV4J0fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_index = {name: i for i, name in enumerate(leagues)}\n",
        "y_val_int = y_val_strat.map(class_to_index).to_numpy().reshape(-1, 1, 1)\n",
        "\n",
        "\n",
        "predicted_classes = y_val_int.reshape(-1, 1, 1) #chatGPT\n",
        "predicted_class_shap = np.take_along_axis(shap_values, predicted_classes, axis=2).squeeze(-1)\n",
        "\n",
        "# Plot SHAP summary - chatGPT\n",
        "shap.summary_plot(predicted_class_shap, X_val_strat, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "LXdZEtG3J0KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOT PART OF THE THESIS\n",
        "(additional experiments)"
      ],
      "metadata": {
        "id": "izIm1epOGXma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Feature Importance methods (permutation)"
      ],
      "metadata": {
        "id": "SqIMSH--FjF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "feature_names = list(X_train.columns)\n",
        "\n",
        "start_time = time.time()\n",
        "importances = rf_model.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
        "\n",
        "forest_importances = pd.Series(importances, index=feature_names)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "ELew_EjYFfIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "start_time = time.time()\n",
        "result = permutation_importance(\n",
        "    rf_model, X_val, y_val, n_repeats=10, random_state=22, n_jobs=-1\n",
        ")\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
        "\n",
        "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IMA3x_rMFopL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Permutation feature importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "result = permutation_importance(rf_model, X_val, y_val, n_repeats=10, random_state=22, n_jobs=-1)\n",
        "perm_imp_df = pd.DataFrame({'Feature': feature_names, 'Permutation Importance': result.importances_mean}).sort_values('Permutation Importance', ascending=False)\n",
        "print(perm_imp_df)"
      ],
      "metadata": {
        "id": "GN2PVCAmFqO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Permutation - Mean Decrease Accuracy\n",
        "importances = []\n",
        "initial_accuracy = accuracy_score(y_val_strat, rf_model.predict(X_val_strat))  # initial accuracy\n",
        "\n",
        "for i in range(X_val_strat.shape[1]):\n",
        "    X_val_copy = X_val_strat.copy()\n",
        "    X_val_copy.iloc[:, i] = np.random.permutation(X_val_copy.iloc[:, i].values)\n",
        "    shuff_accuracy = accuracy_score(y_val_strat, rf_model.predict(X_val_copy))\n",
        "    importances.append(initial_accuracy - shuff_accuracy)\n",
        "\n",
        "accuracy_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Decrease in Accuracy': importances\n",
        "}).sort_values('Decrease in Accuracy', ascending=False)\n",
        "\n",
        "print(accuracy_df)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.barh(accuracy_df['Feature'], accuracy_df['Decrease in Accuracy'], color='skyblue')\n",
        "plt.xlabel('Mean Decrease Accuracy')\n",
        "plt.title('Feature Importance - Mean Decrease Accuracy (All Features)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# Filtered and sorted -- features with importance above threshold\n",
        "threshold = 0.015\n",
        "filtered_df = accuracy_df[accuracy_df['Decrease in Accuracy'] > threshold] \\\n",
        "    .sort_values('Decrease in Accuracy', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.barh(filtered_df['Feature'], filtered_df['Decrease in Accuracy'], color='orange')\n",
        "plt.xlabel('Mean Decrease Accuracy')\n",
        "plt.title(f'Feature Importance - Features with Decrease > {threshold}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1vh9H6ZqFt0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rf_with_top_features(top_ns):\n",
        "    best_results = []\n",
        "\n",
        "    for top_n in top_ns:\n",
        "        print(f\"\\nEvaluating top {top_n} features...\")\n",
        "\n",
        "        selected_features = accuracy_df.head(top_n)['Feature'].tolist()\n",
        "\n",
        "        # mask\n",
        "        X_train_filter = X_train[selected_features]\n",
        "        X_val_filter = X_val[selected_features]\n",
        "\n",
        "        # filter\n",
        "        leagues_to_keep = [\n",
        "            'english_premier_league', 'spain_la_liga', 'italy_serie_a',\n",
        "            'france_ligue_1', 'german_bundesliga', 'nl_eredivisie',\n",
        "            'portugal_liga', 'scotland_prem'\n",
        "        ]\n",
        "\n",
        "        mask_train = y_train.isin(leagues_to_keep)\n",
        "        mask_val = y_val.isin(leagues_to_keep)\n",
        "\n",
        "        X_train_top = X_train_filter[mask_train].reset_index(drop=True)\n",
        "        y_train_top = y_train[mask_train].reset_index(drop=True)\n",
        "\n",
        "        X_val_top = X_val_filter[mask_val].reset_index(drop=True)\n",
        "        y_val_top = y_val[mask_val].reset_index(drop=True)\n",
        "\n",
        "        # Train RF with grid search\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5]\n",
        "        }\n",
        "        grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)\n",
        "        grid.fit(X_train_top, y_train_top)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(X_val_top)\n",
        "        acc = accuracy_score(y_val_top, y_pred)\n",
        "\n",
        "        print(f\"Top-{top_n} features | Accuracy: {acc:.4f} | Best Params: {grid.best_params_}\")\n",
        "        best_results.append((top_n, acc, grid.best_params_))\n",
        "\n",
        "    return best_results\n",
        "\n",
        "\n",
        "top_n_list = [5, 10, 15, 20, 25, 30, 35]\n",
        "results = evaluate_rf_with_top_features(top_n_list)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Top_N', 'Accuracy', 'Best_Params'])\n",
        "print(\"\\nSummary:\\n\", results_df)"
      ],
      "metadata": {
        "id": "MFp1ooxWGBb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF Evaluation with fewer features"
      ],
      "metadata": {
        "id": "StEa6BBPGS66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mask of selected features\n",
        "selected_features = filtered_df['Feature'].tolist()\n",
        "\n",
        "X_train_filter = X_train[selected_features]\n",
        "X_val_filter = X_val[selected_features]"
      ],
      "metadata": {
        "id": "-YAFEHHfGMDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
        "rf_model_filter = RandomForestClassifier(\n",
        "    max_depth = None,\n",
        "    max_features = 'sqrt',\n",
        "    min_samples_leaf = 1,\n",
        "    min_samples_split = 2,\n",
        "    n_estimators = 150\n",
        ")\n",
        "rf_model_filter.fit(X_train_filter, y_train)"
      ],
      "metadata": {
        "id": "_HTivBluGOta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(rf_model_filter, X_val_filter, y_val)"
      ],
      "metadata": {
        "id": "sSZJ6AJqGl_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(rf_model_filter, X_val_filter, y_val, title = \"Confusion Matrix Random Forest\", labels=np.unique(y_train))"
      ],
      "metadata": {
        "id": "DwZDcL31Goj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypertune Filter Model"
      ],
      "metadata": {
        "id": "p3jJikOWGxxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST -- Hypertune\n",
        "#https://www.blog.trainindata.com/random-forest-with-grid-search/\n",
        "def calculate_best_params(model, grid, X_train):\n",
        "    model  = model();\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, cv = 3, verbose = 3, n_jobs=-1)\n",
        "\n",
        "    grid_search.fit(X_train,y_train)\n",
        "\n",
        "    print(\"Best Parameters:\",grid_search.best_params_)\n",
        "    print(\"Train Score:\",grid_search.best_score_)\n",
        "    print(\"Val Score:\",grid_search.score(X_val_filter,y_val))\n",
        "\n",
        "rf_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "calculate_best_params(RandomForestClassifier, rf_grid, X_train_filter)\n",
        "\n",
        "#Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
        "#Train Score: 0.5380968999011225\n",
        "#Val Score: 0.39417518897287684"
      ],
      "metadata": {
        "id": "6t-mFbtzGpAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}